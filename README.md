# ğŸ‘ï¸ Eye Movement and Hand Cursor - Innovative Interaction Technology ğŸ¤²

Welcome to the **Eye Movement and Hand Cursor** project! This cutting-edge application uses eye tracking and hand gesture recognition to control the cursor, providing a unique and intuitive way to interact with your computer.


## ğŸ¯ Project Overview

This project aims to revolutionize user interaction by integrating eye and hand tracking technologies to create a virtual mouse controlled by eye movements and hand gestures.

- ğŸ‘ï¸ **Eye Tracking**: Use your eyes to move the cursor.
- ğŸ¤² **Hand Gestures**: Perform actions with hand movements.
- ğŸ”„ **Seamless Interaction**: Smooth and intuitive user experience.


## ğŸš€ Features

- **Eye Movement Detection**: Precisely track eye movements to control cursor position.
- **Hand Gesture Control**: Use predefined gestures to perform actions like clicking and scrolling.
- **Real-time Interaction**: Instant feedback and control for an immersive experience.
- **Customizable Settings**: Adjust sensitivity and gestures according to user preference.

## ğŸ› ï¸ Built With

- **Python**: For implementing eye and hand tracking algorithms.
- **OpenCV**: For image processing and gesture recognition.
- **Django**: For integrating the frontend and backend functionalities.

## ğŸ’» How to Get Started

1. Clone the repository:
   ```bash
   git clone https://github.com/Harinisenthilkumar/Eye-Movement-and-Hand-Cursor.git
Install the required dependencies and run the application:
bash
Copy code
cd Eye-Movement-and-Hand-Cursor
pip install -r requirements.txt
python manage.py runserver
ğŸ¤ Contributing
Contributions are welcome! Feel free to fork the repository, enhance the existing features, or add new functionalities.

ğŸ“¬ Contact
For any questions or feedback, you can reach out:

GitHub: https://github.com/Harinisenthilkumar
Portfolio:https://66ae3bdaa22e2a9586ea3932--jade-lollipop-e61d63.netlify.app/ my portfolio link
